Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. If in doubt you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.

Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

Linking images and reports/Incluir imagens e relatórios
- You can link a .png or .html file in your answers by typing the name of the file in a separate line. The file must be in the same folder as this TP1.txt file. See the examples below:
- Pode ligar às respostas um ficheiro .png ou .html escrevendo o nome do ficheiro numa linha separada. O ficheiro tem de estar presente na mesma pasta em que está este ficheiro TP1.txt. Por exemplo:

exemplo.png
exemplo.html

PERGUNTAS/QUESTIONS:

Q1: Explain the architecture of your best model for the multiclass classification problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q1; Explique a arquitectura do seu melhor modelo para o problema de classificação de multi-classe, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R1:
Our model for the multiclass classification problem is divided into two parts: the convolutional part and the dense part.
We use convolutional layers because we want the network to capture patterns in the images.
In the convolutional part we have 6 layers, with a number of filters that increases from 16 in the first layer, to 96 in the last convolutional layer. Each filter has a 3x3 kernel.
Each convolutional layer has batch normalization applied to its output, and the ReLU activation function.
The first two layers have 2x2 maxpooling applied to the output of the activation function, before the batch normalization. This is because when the maxpooling was applied to the output of the batch normalization, the values of the categorical accuracy varied a lot, and moving the maxpooling to before the batch normalization fixed the problem.
We apply maxpooling only to the first 2 layers because we didn't want the size of the image to decrease too much, and two maxpoolings showed the best results in the validation error/accuracy.
Between the convolutional part and the dense part is a Flatten(), because dense layers accept 1-dimensional tensors tensors.
In the dense part we have 2 hidden layers, the first with 256 neurons and the other with 128.
We used the ReLU activation function in every hidden layer. We couldn't use the sigmoid function, of course, because of the vanishing gradients problem. We also tested using the leaky-ReLU function, but it produced similar results, so we decided to stay with simple ReLU.
The output layer has 10 neurons with a softmax activation function. This problem is a classification problem with 10 classes, so what we want in the output is an array with the probability of the example belonging to each of the 10 classes, which is what the softmax activation function does.
We could have used 10 sigmoids instead of the softmax, but with the softmax the network doesn't have to learn that there is only one class for each example.
The loss function is the categorical crossentropy. DESENVOLVER AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\||||||||||||||||||||||||||||||||||||||||
We chose to use the Adam optimizer with decay, because it achieved the best results. We used inverse time decay for the learning rate, which was the default decay method before the decay parameter was deprecated.

Q2: Discuss and explain how you selected the best model for the multiclass classifcation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained.
Q2: Discuta e explique como seleccionou o melhor modelo para o problema de classificação multi-classe, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos.
R2:
We started from the neural network we built for the classification problem in the tutorial 3. This network had only two convolutional layers, and thus resulted in overfitting, as we can see in the validation accuracy plot.
overfitting.png
Seeing this, we tried adding more convolutional layers, and with four convolutional layers we got better validation accuracy, sometimes equal to 99% but extremely unstable, as seen in this plot:
unstable4.png
After this, we tried adding even more convolutional layers, but this did not improve the results.
After a few different tries, we experimented with removing maxpooling, and the results started to stabilize. We ended up settling with the first 2 layers having maxpooling before the batch normalization, which showed the best results, as shown in the following plot:
final1.png

Q3: For the multilabel classification problem, explain how you adpated your previous model, what experiments you did to optimize the architecture and discuss your results. Do not forget to explain your choice of activation and loss functions and why this model differs from the previous one.
Q3: Para o problema de classificação com múltiplas etiquetas, explique como adaptou o modelo anterior, que experiências fez para optimizar a arquitectura e discuta os resultados. Não se esqueça de explicar a escolha de funções de activação e custo e porque é que este modelo difere do anterior.
R3:


Q4: Explain the architecture of your best model for the semantic segmentation problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q4: Explique a arquitectura do seu melhor modelo para o problema de segmentação semântica, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R4:


Q5: Discuss and explain how you selected the best model for the semantic segmentation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained. Use the auxiliary functions provided to show the correspondence between your predicted segmentation masks and the masks provided in the test set.
Q5: Discuta e explique como seleccionou o melhor modelo para o problema de segmentação semântica, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos. Use as funções auxiliares fornecidas para mostrar a correspondência entre as máscaras de segmentação previstas e as máscaras no conjunto de teste.
R5:


Q6: (Optional) Discuss the impact on training and overfitting for the two classification problems when using available networks pretrained on ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explain how you used these networks and discuss the effect they had relative to your models.
Q6: (Opcional) Discuta o impacto no treino e sobreajustamento nos dois problemas de classificação se usar redes pré-treinadas no dataset ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explique como usou estas redes e discuta o efeito que tiveram nos seus modelos.
R6:

