Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. If in doubt you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.

Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

Linking images and reports/Incluir imagens e relatórios
- You can link a .png or .html file in your answers by typing the name of the file in a separate line. The file must be in the same folder as this TP1.txt file. See the examples below:
- Pode ligar às respostas um ficheiro .png ou .html escrevendo o nome do ficheiro numa linha separada. O ficheiro tem de estar presente na mesma pasta em que está este ficheiro TP1.txt. Por exemplo:

exemplo.png
exemplo.html

PERGUNTAS/QUESTIONS:

Q1: Explain the architecture of your best model for the multiclass classification problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q1; Explique a arquitectura do seu melhor modelo para o problema de classificação de multi-classe, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R1:
Our model for the multiclass classification problem is divided into two parts: the convolutional part and the dense part.
We use convolutional layers because we want the network to capture patterns in the images.
In the convolutional part we have 6 layers, with a number of filters that increases from 16 in the first layer, to 96 in the last convolutional layer. Each filter has a 3x3 kernel.
Each convolutional layer has batch normalization applied to its output, and the ReLU activation function.
The first two layers have 2x2 maxpooling applied to the output of the activation function, before the batch normalization. This is because when the maxpooling was applied to the output of the batch normalization, the values of the categorical accuracy varied a lot, and moving the maxpooling to before the batch normalization fixed the problem.
We apply maxpooling only to the first 2 layers because we didn't want the size of the image to decrease too much, and two maxpoolings showed the best results in the validation error/accuracy.
Between the convolutional part and the dense part is a Flatten(), because dense layers accept 1-dimensional tensors tensors.
In the dense part we have 2 hidden layers, the first with 256 neurons and the other with 128.
We used the ReLU activation function in every hidden layer. We couldn't use the sigmoid function, of course, because of the vanishing gradients problem. We also tested using the leaky-ReLU function, but it produced similar results, so we decided to stay with simple ReLU.
The output layer has 10 neurons with a softmax activation function. This problem is a classification problem with 10 classes, so what we want in the output is an array with the probability of the example belonging to each of the 10 classes, which is what the softmax activation function does.
We could have used 10 sigmoids instead of the softmax, but with the softmax the network doesn't have to learn that there is only one class for each example.
The loss function is the categorical crossentropy. DESENVOLVER AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\||||||||||||||||||||||||||||||||||||||||
We chose to use the Adam optimizer with decay, because it achieved the best results. We used inverse time decay for the learning rate, which was the default decay method before the decay parameter was deprecated.

Q2: Discuss and explain how you selected the best model for the multiclass classifcation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained.
Q2: Discuta e explique como seleccionou o melhor modelo para o problema de classificação multi-classe, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos.
R2:
We started from the neural network we built for the classification problem in the tutorial 3. This network had only two convolutional layers, and thus resulted in overfitting, as we can see in the validation accuracy plot.
overfitting.png
To try to fix the overfitting we tried to do regularization, namely dropout, but this didn't work.
Seeing this, we tried adding more convolutional layers, and with four convolutional layers we got better validation accuracy, sometimes equal to 99% but extremely unstable, as seen in this plot:
unstable4.png
After this, we tried adding even more convolutional layers, but this did not improve the results.
After a few different tries, we experimented with removing maxpooling, and the results started to stabilize. We ended up settling with the first 2 layers having maxpooling before the batch normalization, which showed the best results, as shown in the following plot:
final1.png

Q3: For the multilabel classification problem, explain how you adpated your previous model, what experiments you did to optimize the architecture and discuss your results. Do not forget to explain your choice of activation and loss functions and why this model differs from the previous one.
Q3: Para o problema de classificação com múltiplas etiquetas, explique como adaptou o modelo anterior, que experiências fez para optimizar a arquitectura e discuta os resultados. Não se esqueça de explicar a escolha de funções de activação e custo e porque é que este modelo difere do anterior.
R3:
When we started the multilabel problem, we hadn't yet arrived at the final architecture for the multiclass classification problem.
So, we started with the architecture we had at that time, which was a convolutional part with 6 layers (16-16-32-32-64-96), and a dense part with 2 layers (128-256). All convolutional layers had batch normalization and max-pooling, in this order.
This architecture gave decent results, achieving 99% validation accuracy after 100 epochs, but being a bit unstable.
first-multilabel.png
Since this architecture was doing very well, we only tried minor tweaks, like removing max-pooling or doing it before the batch normalization, and using less layers. As with the multiclass example, using max-pooling only in the first 2 convolutional layers before the batch normalization gave the best results:
2-max-poolings-before.png
After a few tweaks we settled for an architecture with 5 layers on the convolutional part (32-32-64-96-96), 2 layers on the dense part (256-128), and max-pooling on the first 2 convolutional layers before the batch normalization, which gave these results:
final-architecture-multilabel.png
The activation function of the last layer had to change from the multiclass problem, since it was a softmax. 
Softmax is 1 for only one neuron and 0 for all others, therefore, it can't be used for multilabel classification problems, where we want multiple output neurons to be active. 
So, we chose to use sigmoid activations in the last layer.
By using sigmoids, the activations of the output neurons will all be 0 or 1, but without the constraint of only one being able to be 1. This makes it suitable for multilabel classification.
BINARY CROSSENTROPY WHY AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA

Q4: Explain the architecture of your best model for the semantic segmentation problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q4: Explique a arquitectura do seu melhor modelo para o problema de segmentação semântica, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R4:
For this problem we started with an autoencoder architecture, because AAAAAAAAAAAAAAAAAAAAAAAAA
The autoencoder is an encoder + a decoder. The encoder reduces the dimension of the data, giving us a lower-dimensional representation of the image, and the decoder progressively increases the dimensions of the image, but in our case, we want it to give a mask of the image, so instead of completely reconstructing the image (a 64x64x3 tensor), we want it to return a 64x64x1 tensor in the final layer.
Our autoencoder achieved very good results,
The architecture of our first model first has a convolutional layer with 32 filters, that turns the 64x64x3 input tensor into a 64x64x32 tensor.
After this, it applies max-pooling to reduce the size of the image to 32x32, resulting in a 32x3x32 tensor.
Then, two convolution layers with 8 filters are used, which change the shape of the tensor to 32x32x8.
After this, the decoding starts.
First, two convolution layers are applied, the first with 16 filters, and the second with 32, resulting in a 64x64x32 tensor.
Finally, since we want a 64x64x1 image, we use a convolution layer with only 1 filter, which reduces the tensor to 64x64x1.


Q5: Discuss and explain how you selected the best model for the semantic segmentation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained. Use the auxiliary functions provided to show the correspondence between your predicted segmentation masks and the masks provided in the test set.
Q5: Discuta e explique como seleccionou o melhor modelo para o problema de segmentação semântica, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos. Use as funções auxiliares fornecidas para mostrar a correspondência entre as máscaras de segmentação previstas e as máscaras no conjunto de teste.
R5:

When we started to develop this part of the project, since we didn't really understand autoencoders very well, we viewed the problem like a multilabel classification problem, with 64x64 output neurons with sigmoid activation, corresponding to each pixel in the mask. 1 would be white, 0 would be black. This actually worked suprisingly well, achieving a validation accuracy of 95%, and the masks themselves also didn't look bad.
MOSTRAR IMAGENS DO MULTILABEL
But after understanding autoencoders, we realized they would be better for tackling this problem.
We started with the autoencoder architecture given in the lecture slides, and removed the dense part as it was causing some issues.
This initial architecture proved very successful, getting 99,9% accuracy and giving excelent masks:
IMAGENS DAS MASKS DO MODELO FINAL
Seing these results we didn't change much, as anything we tried to change either didn't do anything, or made the results worse. Things we tried changing were:

Q6: (Optional) Discuss the impact on training and overfitting for the two classification problems when using available networks pretrained on ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explain how you used these networks and discuss the effect they had relative to your models.
Q6: (Opcional) Discuta o impacto no treino e sobreajustamento nos dois problemas de classificação se usar redes pré-treinadas no dataset ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explique como usou estas redes e discuta o efeito que tiveram nos seus modelos.
R6:

